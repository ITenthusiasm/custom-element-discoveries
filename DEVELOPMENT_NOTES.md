# Development Notes

My more-detailed notes on certain design decisions that I made for the components in this codebase.

## What's the Motivation behind Using `static` Methods as Event Handlers? (2025-05-12)

As as rule, we prefer using `static` event handlers in our Web Components whenever possible. The reason for this is quite simple: If you have a single function that _every_ instance of your component uses, then you'll save _significantly_ on memory usage. For example: If 100 `SelectEnhancer` components are rendered to the DOM, only _one_ `#handleDelegatedOptionClick` "function" (`static` method) will be created. This function will be referenced by all of the corresponding event listeners registered for the `SelectEnhancer`.

By contrast, consider the `ComboboxField.#handleTypeahead` function: It is an arrow function that is uniquely created and assigned _every time the component is instantiated_. Thus, if we create 100 `ComboboxField`s, we'll have 100 `#handleTypeahead`s -- one for each instance of the component (even though they do virtually the same thing). This is far less performant when it comes to memory. Why use arrow functions in that case? Because sometimes we need access to `this` inside event handlers.

Now, you might think that it would be better to use a regular method instead of an arrow function to resolve this problem. Doing so would provide access to `this` without creating `N` instances of the same function for each instantiated component. (The method would simply use different values for `this` based on the component instance.) However, when it comes to registering event handlers (`this.addEventListener("click", this.handleClick`), we have to use `this.handler.bind(this)` to preserve a proper reference to `this`. And unfortunately, doing so would cause 100 `handler`s to be created anyway. The approach would technically have _slightly_ better memory usage than arrow functions, but the inconvenience it causes (having to maintain a consistent reference to the bound function between `connectedCallback` and `disconnectedCallback`) isn't really worth it unless memory becomes a greater issue.

So basically, because of memory usage, we prefer `static` methods whenever possible. We make these methods private because they're solely the concern of the owning class/component, and they should not be tampered with.

## Why Loop through **_Every_** `option` during Filtering? (2025-05-06)

It's not great that we have to loop through **_all_** of our `option`s whenever we want to filter them in `filter` mode. However, there isn't really another alternative. We need to meticulously handle the `option`-searching feature in such a way that `option`s are dynamically revealed _or_ hidden as the filter is updated -- **_reliably_**.

"Reliably" is the keyword there. It would be great if we could filter only a subset of our `option`s. For example, if the user already has the string `"ap"` in the searchbox, it would be awesome if we could search _only_ through the `option`s that are _currently_ in the set of revealed `option`s. This would be much faster, but the problem with this idea is that it isn't reliable. For one thing, if the user moves the cursor backwards before adding new characters, then the current set of filtered `option`s is no longer valid and we need to search through all of the `option`s again anyway. (This is because the filter will now be, for example, `"a?p"` instead of `"ap?"`) The various kinds of [`inputType`s](https://developer.mozilla.org/en-US/docs/Web/API/InputEvent/inputType) also complicate things. For instance, how would your filtering logic change if someone used `deleteWordBackward`?

At the end of the day, your implementation will be much simpler and much more practical if you loop through the entire set of `option`s whenever the filter is updated. If you really want a Swiss cheese performance gain, use a Trie. (See [Wikipedia](https://en.wikipedia.org/wiki/Trie) and [ThePrimeagen](https://frontendmasters.com/courses/algorithms/tries/).)

### Why Use `data-filtered-out` Instead of Dynamically-creating (or -arranging) DOM-content?

Related to the issue of filtering `option`s, it is important to determine how `option`s are hidden/displayed during filtering. In the past, with React, we kept an internal array of all the `option`s as `{ label: string; value: string }` objects. When the user updated the searchbox with a new filter, we would loop through all of the objects in this array (which is unavoidable, like we mentioned earlier) to determine the `ReactElement`s that should be rendered to the DOM.

Unfortunately, this approach is _very_ wasteful. It effectively means that you are deleting/creating new DOM nodes (and Virtual-DOM objects in React's case) every time the filter changes. But why do that? Isn't it better to _reuse_ the same set of `option` elements and display or hide them as needed?

That's the idea behind our `data-filtered-out` approach. We don't delete/re-create `<combobox-option>` elements when the filter changes. Instead, we create all of the `<combobox-option>`s once and only once. Then, when the filter changes, we toggle a `data-filtered-out` attribute on each of these `option`s, and this attribute (when paired with CSS) determines whether or not the `option` will be displayed to the user. This is much better for the memory-management of our application! No nodes have to be deleted (and garbage collected) or re-created -- ever! And toggling attributes is very cheap. :&rpar;

HOWEVER! There is one noteworthy flaw with this approach (or at least, with our _original_ implementation of it)... Specifically, our `ArrowDown`/`ArrowUp` searching logic takes a hit... If, while we're filtering through `option`s, we're simply _hiding_ `option`s instead of removing them from the DOM/`listbox`, then `Element.nextElementSibling()` will no longer be guaranteed to give us a valid `option`. That is, the method might give us an `option` that has been filtered! So then, we have to enter a loop and keep looking for the next sibling until we find one that _isn't_ filtered out. As the number of matching `option`s decreases, the amount of `option`s that have to be searched through in this loop increases. That means our `ArrowDown`/`ArrowUp` search logic is no longer `O(1)` (a simple `Element.nextElementSibling()` call), but `O(N)` (_looped_ calls to `Element.nextElementSibling()`)!

Now, depending on how the developer using the component orders their `option`s (e.g., if everything is in alphabetical order), this may not be as much of a practical problem. But that isn't a guarantee. Additionally if someone wants to play with the arrow keys at the bounds of the filtered `option`s list, then we can still run into `O(N)` issues where the component keeps searching until `Element.nextElementSibling()` returns `null`.

Enter [WAI-ARIA's solution](https://www.w3.org/WAI/ARIA/apg/patterns/combobox/examples/combobox-autocomplete-list/#javascriptandcsssourcecode). We thought it was silly at first, but actually it's quite brilliant and memory-considerate when you think about it. "On mount" (technically, on `construct`ion of their utility, which attaches itself to an already-mounted DOM node), their `ComboboxAutocomplete` class caches all of the `option` elements in an internal array. As the user filters through the existing set of `option`s, the elements in this internal array are `append`ed to the `listbox` element if they match the search criteria. And the `listbox` always has its `children` emptied before performing this search + append logic.

On the surface, this might sound odd, but it isn't. Just like us, they create all of the `option` elements _once and only once_. But unlike us, they dynamically change the content of the `listbox` element as the user filters through the `option`s. Consequently, as the `ArrowUp`/`ArrowDown` keys are pressed, the code only has to do `Element.nextElementSibling()` (and the like). This keeps the logic for `ArrowDown`/`Home`/etc. at O(1). (Note that WAI-ARIA doesn't actually seem to leverage methods like `Element.nextElementSibling()`, but they _could_ if they wanted. That's what's important.)

Although the `listbox` has its children reset on each change to the filter with this implementation, there are fewer memory concerns here. The _references_ to the nodes themselves remain in the internal array, and these elements are never destroyed or recreated. Thus, the only thing that changes on a per-filter basis is the Tree Relationship between all of these nodes. (You can probably argue that there's a performance cost to continuously establishing and disassembling these relationships, but that cost will be much smaller than that of creating and deleting new DOM nodes continuously.)

So... WAI-ARIA's solution has O(1) performance when it comes to moving fowards or backwards in a filtered `listbox`. And their solution doesn't delete or recreate DOM nodes... Should we switch to their solution? Well, not necessarily.

Literally, while writing this Note, it dawned on me that I could leverage WAI-ARIA's approach in my own way. Instead of creating an internal array for the list of `option`s, I can let `listbox.children` itself be the "cached array". And instead of using `Element.nextElementSibling()` to find the next matching `option` in `filter` mode, I can keep track of an internal `#filteredOptions` array. When we loop through `listbox.children` in the event handler for filtering the `option`s, we can `push` all matching `<combobox-option>`s into the `#filteredOptions` array. This array can then be referenced to find the next (or previous) `option` that matches the current filter when a user presses `ArrowDown`, `ArrowUp`, or the like.

This solution requires keeping track of the `#currentFilterIndex` as the user navigates through the filtered `option`s with the keyboard. So `ArrowUp` would decrement the index, and `End` would set the index to `#filteredOptions.length - 1`. This index would also have to be reset to `0` every time the filter is changed.

This approach is very simple to implement, and it's arguably more performant as well. Why? Because we'll not only skip creating/deleting DOM nodes, but we'll also skip establishing/breaking the relationships between those nodes. WAI-ARIA was already tracking 2 separate arrays (`allOptions` and `filteredOptions`) in addition to managing `listbox`'s children; so this should be faster. The only downside with our implementation is that we have to keep track of `#currentFilterIndex`, but that shouldn't have any significant impacts on performance or memory, and in the end the `data-filtered-out` approach should still come out faster.

#### What about `Trie`s?

Bringing a `Trie` into the mix would complicate the `data-filtered-out` approach because the data structure caching the `option`s would no longer be an array. If we were adding/removing nodes from the DOM (_without_ recreating them), then we could recursively search a `Trie` for all matching `option`s and then append them to the `listbox`. Unfortunately, this means that the `listbox` would need to have its children replaced on every filter update. Not only is that a potential performance hit, but it conflicts with our current approach of (conditionally) modifying the `combobox`'s value as new `option`s are added to (or removed from) the owned `listbox`. (At least, the conflict exists at the time of this writing.)

However, there might be a workaround that is still compatible with our current approach, and that allows us to leverage `data-*` attributes to get the job done: You could have all `option`s hidden by default. Then, as the user searches, you could do a breadth (or depth) first search to get all of the `option`s that should be _filtered in_. (In that case, we'd probably have something like a `data-matching` attribute -- instead of a `data-filtered-out` attribute -- to reveal these `option`s.)

These `option`s wouldn't need to be created or destroyed, and they wouldn't need to be moved in-or-out of the `listbox`. They could be left within the `listbox`, and the `Trie` data structure could simply reference those DOM nodes. (The existence of a DOM node on a `Trie` node could be used instead of an `isWord` property to verify that a given path in the `Trie` represents a valid `option`.) As the `Trie` is being searched, it can push valid `option`s into an array of `#filteredOption`s. When the search through the `Trie` completes, the `option`s in this array could all be toggled "on" with a `data-matching` attribute (or the like). As with before, a `#currentFilterIndex` would still be required here to allow for navigation with `ArrowUp`/`ArrowDown`/etc.

When the user changes the filter (or when the user leaves the `combobox`), all of the `option`s in `#filteredOption`s would need to have their `data-matching` attributes removed. And `#filteredOptions` would need to be emptied before the `Trie` traversal that re-populates the array starts.

When the user empties the filter (and optionally, when they leave the `combobox`), all `option`s would need to have their `data-matching` attributes removed. Since the performance would already be `O(N)` for the `Trie` in this scenario (`N` being the number of `option`s), it's probably fine to leverage `Element.nextElementSibling()` for that (unless the performance of `Trie` traversal is somehow faster than the performance of `DOM` traversal). Of course, if performance was really a concern, you could simply refuse to display any `option`s until _after_ the user starts searching.

The performance resulting from this approach would probably be better than our current implementation, but we'd need to do some measurements to verify that. This solution would require slightly more effort, but not too much. Most of the complexity would be around managing the `#filteredOptions` array properly and emptying/updating it at the right times. But even if this doesn't introduce too much complexity, it's still added complexity. And another cost to consider is that implementing a `Trie` that's used in the `combobox` would increase the bundle size of the component. So although this solution might be effective and performant, it probably isn't worth addressing unless someone using the component is working with an enormous amount of `option`s and needs such performance gains.

Notice that we're intentionally avoiding things like `querySelectorAll` here, because that would require visiting every single node and would thus be vastly less performant.

## Pros and Cons of Allowing `ComboboxOption.attributeChangedCallback()` to Run When Its Owning `combobox` Is Present Instead of When It `isConnected`

Originally, the `ComboboxOption`'s `attributeChangedCallback()` was only allowed to run after the component was mounted. However, we thought it might be a good idea to relax the constraints by allowing the callback to run if the owning `combobox` existed (which -- based on how the `ComboboxOption` class is written -- implies that the owning `listbox` also exists). In the end, we found that there were pros and cons to this approach (at least with respect to our current implementation of the component). Below are the pros/cons we discovered, and the final decision that we made.

### Cons

1. There are performance concerns if the `selected` attribute is supplied to multiple `combobox-option`s on mount. (This is unrealistic and technically not allowed in the `<select>` spec anyway -- at least for its single-select variant). There are also performance concerns if the `value` attribute is on every `combobox-option` on mount. (By contrast, this is very realistic, for example, with a U.S. State selector with `value`s that corresponds to IDs on the backend). Changing these attributes can trigger the owning `ComboboxField`'s value update logic. (Can we evaluate how much of a concern the value selection logic is?)
2. We still won't be able to support the case of newly-added `option`s causing `combobox` value updates (like the `<select>` element) because the related `MutationObserver` is only setup after the `ComboboxField` is mounted to the DOM. (I don't think there's a safe way to handle this that doesn't egregiously leak implementation details?)

### Pros

1. Could it maybe help with setup/mounting logic if people don't care about progressive enhancement and they just want to have a DOM that uses a `combobx-container` + `combobox-field` + `combobox-option` directly?
2. In general, obviously this will add more flexibility for DOM manipulation pre-mounting.

### Additional Thoughts

Currently, the `ComboboxOption.attributeChangedCallback()` will only run if the `ComboboxOption` `isConnected` to the DOM (implying that the rest of the "Combobox Unit" is already connected to the DOM as well). Theoretically, we could allow the callback to run at any time as long as its owning `combobox` exists. This would _slightly_ improve the component's flexibility as well as the process of setting up the entire "Combobox Unit" as a whole. Particularly, it would simplify the process of setting the `ComboboxField`'s default value when the "whole unit" is mounted (i.e., during the container/adapter component's `connectedCallback`), and it would enable to the `ComboboxField`'s value to updated as its **_currently-owned_** `ComboboxOption`s have their `selected` properties changed. However, the gains acquired here are likely negligible. Here's why:

#### 1&rpar; Mounting Logic Will Always Be Needed

First of all, the entire "Combobox Unit" will always require an "Adapter/Container Component" which sets up the proper a11y relationships between the various parts of the Combobox. (The container component might even perform additional logic as well, such as transferring attributes or removing unsupported children.) Since the logic for calculating a `ComboboxField`'s "default value" onMount (i.e., during the container's `connectedCallback`) is simple, why not let developers write the logic themselves in the same place where the a11y setup logic written?

On that note, the real goal that we're trying to achieve here is feature-parity with the native `<select>` element. "If a `<select>` element that A&rpar; isn't connected to the DOM and B&rpar; has pre-existing `<option>`s has a new `defaultSelected` option added to it, why can't our Combobox Component?" That's the idea. However, perfect feature parity with the `<select>` element in this regard is impossible.

For this to work, our `ComboboxField` would have to start observing the children of its `listbox` immediately after it's created. But the `ComboboxField` doesn't know the context in which it was created, and so it doesn't know for certain whether the `listbox` that it's supposed to own exists yet. The only component that has said information is the Adapter/Container Component that's setting everything up. But again, that brings us back to putting everything in the developers' hands when they build their own Adapter/Container components.

Allowing the `ComboboxOption.attributeChangedCallback()` to run as long as an owning `combobox` exists gets us a _tiny_ step closer to feature parity with the `<select>` element. In particular, if `ComboboxOption`s which are _already associated_ with a `ComboboxField` have their `selected` properties updated _without the whole "Combobox Unit" being connected to the DOM_, then we would still be able to support value updates in said scenario. But again, who is practically going to be updating `ComboboxOption` values/states in some random `DocumentFragment` that exists outside of an Adapter/Container component?

The ultimate question arising here is this: What _practical_, _noticeable_ value is being provided to people by enabling `ComboboxOption.attributeChangedCallback` to run even if it isn't connected to the DOM?

#### 2&rpar; JS Frameworks Might Break Expectations

When it comes to JavaScript frameworks, we don't have immediate insight into how various frameworks operate. For example, if React creates elements, attaches them to their parents, _and then_ modifies their attributes (based on the supplied JSX props), then our update to the `ComboboxOptoin.attributeChangedCallback()` would allow the `ComboboxField`'s value can be initialized correctly in the event that people want to use all 3 parts of the "Combobox Unit" (`Field`, `Option`, and `Container`/`Adapater`) directly instead of relying on a `<select>` element. **_However_**, if React creates elements, modifies their attributes, _and then_ attaches them to their parents, then there's a chance that all of the value initialization will not be augmented by the `ComboboxOption.attributeChangedCallback()` (because the `option` won't have an owning `combobox` until _after_ it's attached to its parent `listbox`). In that case, `ComboboxOption.attributeChangedCallback()` has provided minimal value to _some_ developers (e.g., a fraction of all the pure-JS devs), but it has also _slowed_ the mounting/intialization process for _all_ developers (regardless of whether or not they use JS frameworks). 👎🏾

### Conclusion

There's probably more that could be said here, but these are the considerations that led to our decision _not_ to refactor `ComboboxOption.attributeChangedCallback()` so that it no longer had to wait until it was connected to the DOM. We just don't see any practical benefits to such a refactor, and there is performance cost to said refactor (even if the cost is minimal). If this **_really_** seems to be a big need in the future, we can revisit this decision.
